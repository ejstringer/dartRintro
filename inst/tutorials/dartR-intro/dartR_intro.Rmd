---
title: "Getting Started with dartR (ebook)" 
author: "The dartR Team"
date: | 
    ![](images/dartR7.png){width=6cm}
output:
  learnr::tutorial:
    progressive: true
    allow_skip: true
    theme: "cerulean"
    highlight: "tango"
    css: ./css/dartR_style.css
runtime: shiny_prerendered
description: "Introduction to dartR - using the Canberra grassland earless dragon as an example."
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE,
	collapse=TRUE
)

#necessary to render tutorial correctly
library(learnr) 
library(htmltools)
#options(repos = BiocManager::repositories())
library(dartR.data)
library(dartR.base)
library(dartR.sexlinked)
gl.set.verbosity(3)

library(dartRintro) # for tutorial data

```


## Introduction {data-progressive=FALSE} 

This is your hands on introduction to [dartR](https://github.com/green-striped-gecko/dartRverse?tab=readme-ov-file#dartrverse-). The worked examples and exercises in this tutorial correspond to the [[Intro to dartR ebook](http://dartr.biomatix.org/dartR)]{style="color:#ff0000;"}. There are also accompanying [AI podcast summaries](https://public.3.basecamp.com/p/Dp1F2egZGXY5siDf1MPFqyyg) for all the chapters, which you should definitely check out if you are more of an auditory learner.

If you can't see the left sidebar, you just need to make the tutorial panel wider.

### R code box

Throughout this tutorial there will be interactive R scripts/consoles (like the one below). This is like a mini version of R running within this tutorial. But since we are already in R, you can also follow along in your own console and start writing your own code in the source panel. You could even try testing some of what you learn on your own data.

But first, try running the code below (press the button that says *Run Code*)

```{r ex, exercise=TRUE}
# Press the Run Code button to run this code
1+1
```


### 

It is worth noting that each R code box is independent, so code you ran in one will not be recognised by another. Don't worry though, we have done some fancy coding in the background for you to continue along, keeping track of the tasks performed before hand. 

###

For the worked examples, we‚Äôve kept things simple: you only need to click the *Run Code* button and review the output. That said, if you‚Äôd like to experiment by editing the code and rerunning it to observe the effects, we strongly encourage you to do so.

### Google group

Any troubles or tribulations with coding in dartR, we have a great community that can be found on the [dartR google group](https://groups.google.com/g/dartr).

### Start Over

While going through the worked examples your progress will be saved, if at any point you would like to refresh the tutorial and start over, the <small>[Start Over]{style="color:#a3a3a3; font-family:'Jaldi', sans-serif;"}</small> button is located at the very bottom of the left sidebar, below the tutorial content.

### Worked examples and exercises

The first part of this tutorial are the worked examples, where we walk you through the process step by step. Following the worked examples you will get the chance to test your knowledge with the exercises, using real data to process datasets that have been used in scientific literature! 

###

One final note, don't forget that all aspects of the material are beneficial for learning. The ebook for being introduced to the theory and methods, the worked examples to gain experience in the application, and finally the exercises to apply everything you have learned.

### Let's get started!

Alright! Get started with your first worked example. After that head back to the ebook and get ready to start working through the worked examples and exercises back here when prompted.

<p>Good luck on your Pop Gen journey! üòÅ</p>


## Worked Ex 1-1: Getting organised
###

A good first step on any data analysis journey is to get a little organised. RStudio's projects are a great way to do that. Let's create a project for this ebook (you can use the same project for all the worked examples and exercises too!).

### Create RStudio project

You can create a project in six easy steps (see fig below):

  1. Navigate to the [File]{style="color:#a3a3a3; font-family:'Arial'"} tab at the top of RStudio and select [New Project...]{style="color:#a3a3a3; font-family:'Arial'"} 
  
  2. Select **New Directory**
  
  3. Then select [New Project]{style="color:#a3a3a3; font-family:'Arial'"} at the top of the list
  
  4. The next step is to name your project (i.e. folder name - how about *learning_dartR*)
  
  5. Then choose a location on your computer where you want to save your project ([Browse...]{style="color:#a3a3a3; font-family:'Arial'"} for easy navigation)
  
  6. Finally, all you need to do is press **Create Project**
  
  
![](images/project.png){.class height="750"}

### Folder structure

The next way to get organised is to have a good folder system, this is the folder system I recommend. 

- code (r scripts)

- data (raw data - READ ONLY)

- figures (figures created)

- output (data created)

###

You might have additional folders but these are a good start.

you can run the below code to generate the folders (run the code `getwd()` to double check they will be created where you want them) 

```{r eval=FALSE}
lapply(c('code', 'data', 'figures', 'output'), dir.create)
```

### Organising scripts

A nice aspect of R scripts in RStudio is that there is a way to create sections when writing code, similar to Microsoft Word headings. First open a new file: [File | New File | R Script]{style="color:#a3a3a3; font-family:'Arial'"}  

###

To define a heading you use hash symbols (# = level 1 heading, ## = level 2 heading, etc...) followed by the heading name and then at least four dashes. 

Here is an example of what it would look like

```{r}
# Heading 1 ------------------

## heading 2 ----

### heading 3 ----
```


You can also use ctrl + Shift + R as a shortcut to define level 1 headings.

###

A great feature is that by clicking the outline icon in the top-right corner of your R script (highlighted by the red arrow in the figure below), you can view all the headings in your script. This outline also allows you to quickly navigate to different sections of your code by selecting the corresponding headings.

![](images/outline.png)

###

These are all just ways to help you keep organised. Apply them as you see fit. 

Now lets get into some actual coding!

## Worked EX 2: Optional
###
If you are familiar with R you can proceed to Worked Ex 3. 

###

Although we provide a chapter on R coding there are many R tutorials out there already. If you are new to R we recommend going through the [R Programming](https://github.com/swirldev/swirl_courses) course from the r package **swirl**. It teaches you R in your console. 

Here is the code to get started.

```{r eval=FALSE}
library(swirl)
install_course("R Programming")
swirl()
```

###

Got the hang of R? If so, let‚Äôs move on!

## Worked EX 3: data and map
### 
It is time to start working in the dartRverse! Welcome!

###

In these worked examples, we‚Äôll walk you through how to prepare genetic data for analysis using the Canberra grassland earless dragon (Tympanocryptis lineata). These little dragons are critically endangered and now survive in just a few remaining patches of natural temperate grassland in the ACT. Refer to [ebook chapter 3](http://dartr.biomatix.org/dartR) for more details

###

Here is a map of the remaining populations.

```{r echo=FALSE}
#devtools::install_github("r-spatial/mapview")
#gl.map.interactive(tympo.gl)

library(leaflet)

m<-leaflet() %>% addCircles(lng = tympo.gl@other$latlon$lon,
                         lat = tympo.gl@other$latlon$lat,
                         color = c('red', 'blue','green', 'yellow')[as.numeric(tympo.gl@pop)]) %>% 
  addTiles(urlTemplate = 'http://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png')
 m 
```

[<small>*Data modified for educational purposes*</small>]{style="color:grey"}

###

It is worth noting that we have modified the data heavily for sake of illustration and they are provided for educational purposes only.

###

Alright, time to bring the data into R --- let's get started!

## Worked Ex 3-1: Load and save

###

Given the low number of individuals remaining in the wild, management's main concern is whether the dragons are losing genetic diversity. **But before we can get into a genetic assessment of the species, there are a number of important steps to go through before hand**.

### Working directory

A first step is to make sure you have set your working directory. If you are in a project the working directory should be the folder location of your project. Refer to worked Ex 1-1 on creating projects. Alternatively, you can use `setwd()`.

### Download raw data

Let's start by downloading the SNP data and associated metadata and saving them in your project folder, or better in a folder called **data**. 


- *link to SNP file*. This is the set of SNP data for CGEDs, in 2-row format as would be supplied by [Diversity Arrays Technology Pty Ltd](https://www.diversityarrays.com).


- *link to metadata file*. Recall that the individual metadata comprise attributes assigned to each individual.


### Read the data into dartR


Read the data from [Report_DTym25-13579_SNP_2.csv]{style="color:blue; font-family: 'Courier New';"} into a dartR object and assign the individual metrics using `gl.read.dart()`

```{r, eval = FALSE}
gl <- gl.read.dart("./data/Report_DTym25-13579_SNP_2.csv",
                   ind.metafile="./data/Tympo_metadata.csv")
```

###

```{r datainput, echo = FALSE, cache=TRUE}
gl <- gl.read.dart(filename=system.file("extdata", "Report_DTym25-13579_SNP_2.csv", package = "dartRintro"),
                   ind.metafile=system.file("extdata", "Tympo_metadata.csv", package = "dartRintro"))
```
###

This is the output you should see when reading in the data. It provides an overview of the steps taken during the import process. Pay particular attention to any messages about samples that could not be found in the metadata, as these will not be loaded. If this occurs, you may need to locate and add the missing metadata for those individuals to the `ind.metafile` file. 

###

We successfully read in the dragons genetic data, now it is ready to interrogate.

### Save 

Just before we do, it is good practice to save your data in binary format after the initial load. This ensures much faster access in future R sessions.

```{r eval=FALSE}
saveRDS(gl, 'tympo_genetic_data.rds')
```

###

You can also save it in a folder called **output** with the below code, assuming **output** is a folder in your working directory.

```{r eval=FALSE}
saveRDS(gl, './output/tympo_genetic_data.rds')
```

###

Make sure you name the data something descriptive and reasonable. 

###

Great all saved, let's move on!

## Worked Ex 3-2: dartR object
###

Let's examine the contents of the Tympo dartR object.

### 

Just before we do, lets do a quick refresher of what a dartR object actually is, of course if you want more background check out [ebook chapter](http://dartr.biomatix.org/dartR) 3.

### 

A *dartR* object is effectively a data structure used to efficiently store and analyse large genetic marker data. It includes the allelic state for each SNP called and for every individual genotyped.

### 

Additionally it also includes the metadata associated with the individuals genotyped and the SNP loci called. That's a lot of information! So lets learn how to interrogate our dartR object.

### Data overview

First let's confirm our `gl` is a dartR object using `class()`. 

```{r gl, echo = FALSE}
gl <- tympo.gl

```


```{r x3e1, exercise=TRUE, exercise.setup = "gl"}
class(gl)

```


###

Great! It says it is a *dartR* object from the package **dartR.base**.

###

Now we can examine `gl`, we simply need to type its name

```{r x3e2, exercise=TRUE, exercise.setup = "gl"}
gl

```

###

It provides us with a lot of useful information, the number of genotypes, which is referring to the number of individuals, and the number of SNPs. Just to name a few. 

###

Another useful way to get an overview of the data is the basic report function,
`gl.report.basics()`. Within the function you can include the argument `verbose =` and set it as either 0, 1, 2, or 3, depending on the detail of output you want. Let's try with verbose equal to 1.


```{r x3e3, exercise=TRUE, exercise.setup = "gl"}
gl.report.basics(gl, verbose = 1)

```



###
That is a lot of output, and verbose is only set to 1. Setting verbose to 0 will result in no output. Some useful bits of information are sample size as well as the percentage breakdown of 0s, 1s, 2s, and NAs in the data. Do you remember what these stand for?

###

If not refer back to the ebook. Otherwise let's keep moving.

## Worked Ex 3-3: Ind metrics
###

Let's get familar with some of the most important components to our data. We can use `nInd()` to remind ourselves of how many individuals are in the data.

```{r x3e4, exercise=TRUE, exercise.setup = "gl"}
nInd(gl)

```


###

Just as expected `r nInd(gl)` individuals.

###

The next important component is the number of populations, we can check this using `nPop()`.

```{r x3e5, exercise=TRUE, exercise.setup = "gl"}
nPop(gl)

```


###

That's interesting, if we look at the map under the [data and map]{style="color:#cc9900"} tab it shows only four populations. 

###

Let's check what the population names are using `popNames()`, to try and figure out what is going on.

```{r x3e6, exercise=TRUE, exercise.setup = "gl"}
popNames(gl)

```



###

Ok, that makes more sense, we have a population called Unknown, so not an actual population. Let's check how many individuals are in this *unknown* population. 

###

We can check this using `pop()`, which lists each individuals' population, and then run it within `table()`, which counts the number of values. 

```{r  x3e7, exercise=TRUE, exercise.setup = "gl"}
table(pop(gl))

```

###


Well that's good to know, it is just the one individual with an unknown population.

###

Let's do a bit of fancy coding to figure out its id. we can use the function `indNames()` and square brackets with a conditional statement where `pop(gl) == 'Unknown'`. 

```{r x3e8, exercise=TRUE, exercise.setup = "gl"}
indNames(gl)[pop(gl) == 'Unknown']

```

###

Alright, that‚Äôs not very revealing. Let‚Äôs dig deeper into the individual-level data to see what we can learn about our unknown individual.

###

dartR objects store individual metadata, which can seem a bit tricky to access at first. But don‚Äôt worry, it‚Äôs simpler than it looks! All you need is the correct address: the individual metadata is located at `gl@other$ind.metrics`.

###

We can check the names of our columns in the metadata using `names()`. Another useful function for a quick overview of a dataframe is `head()` which shows you the column names and the first six entries. 

```{r x3e9, exercise=TRUE, exercise.setup = "gl"}
head(gl@other$ind.metrics)

```

###

We have quite a lot of information for our dragons. Notably, we have latitude and longitude data for any distance-based analyses, as well as sex information, which will be key later when we report on sex linkage.

###

Great now lets check the info about our unknown individual. We can use the same condition as we did before but now the square brackets come after the `gl@other$ind.metrics` and need a comma to distinguish between rows and columns, remember `[rows, columns]`.

```{r x3e10, exercise=TRUE, exercise.setup = "gl"}
gl@other$ind.metrics[pop(gl) == 'Unknown',]

```


###

All we know is that it is a Canberra grassland earless dragon...

###

Alright, I think it is time to check out some of the genetic data.

## Worked Ex 3-4: Loc metrics
###

Let's start by undertaking some basic diagnostics. First let's remind ourselves how many loci are in our dataset, using `nLoc()`.

```{r x3e11, exercise=TRUE, exercise.setup = "gl"}
nLoc(gl)
```


###

Hmm, that seems like a surprisingly low number of SNPs. I‚Äôm used to seeing counts in the tens of thousands. Perhaps the data were altered, or maybe the additional file with more SNPs wasn‚Äôt provided. DArT typically sends two or even three files when there are more than 50,000 SNPs.

###

Ah, that‚Äôs right, these data have been modified for educational purposes. Keep in mind that in real datasets, you should expect far more SNPs, which also means longer analysis times. 

###

To get a better understanding of how the SNP data are stored we can use `as.matrix()` to see the actual state of the SNPs for each individual. 

###

To make it a little easier to visualize lets look at a subset of individuals and SNPs, we use square brackets for this, `[individuals, SNPs]`. Let's display the genotypes for the first 20 individuals and the first 3 loci. 

```{r x3e12, exercise=TRUE, exercise.setup = "gl"}
as.matrix(gl)[1:20,1:3]

```

###


There is not much variation in the first two loci, they are either coded as 0, which indicates a homozygote for the reference allele, or NA for missing. Loci three has more diversity, with homozygotes for both the reference (0) and alternative (2) alleles as well as a few heterozygotes (1).

###

Each locus contains some missing data, but so far we‚Äôve only seen the first 20 individuals. How much missing data does each locus actually have? We can check this by examining the locus metrics.

###

The locus metadata included in the dartR object are those provided as part of your Diversity Arrays Technology report and read in using `gl.read.dart()`. The locus metadata are held in an R dataframe that is associated with the SNPs as part of the dartR object.

###

The loc metrics are similarly located as the ind metrics, `gl@other$loc.metrics`. Let's first look at the names of the loc metrics using `names()`.

```{r x3e13, exercise=TRUE, exercise.setup = "gl"}
names(gl@other$loc.metrics)

```


###

There is quite a bit of information in there. We are interested in the first three loci's rate of missing data, i.e., call rate. Therefore, we are interested in the `CallRate` column. 

###

We can access columns just like with any other dataframe, using `$`. We can then use `[]` to subset the first 1:3 loci.

```{r x3e14, exercise=TRUE, exercise.setup = "gl"}
gl@other$loc.metrics$CallRate[1:3]

```

###

Which locus has the most missing data?

###

Rather than just inspecting the first three loci, let‚Äôs visualize the distribution of call rates across all loci. We can do this by creating a histogram using the `CallRate` column with the `hist()` function, instead of subsetting.

```{r x3e15, exercise=TRUE, exercise.setup = "gl"}
hist(gl@other$loc.metrics$CallRate)

```

###

Most loci have a call rate close to 1, which is great! This indicates that we‚Äôll retain a large number of high-quality loci after filtering (which we will get to later in Chapter 5).

###

By now, you should have a good feel for the data. Let‚Äôs take the next step and dive into some reporting and data manipulations.

## Worked Ex 4-1: Report
###
Now it is time to get our SNPs ready for analysis. We will use the report functions. In each case, think about what threshold you might define to discard loci or individuals with poor quality (quality control).

###

dartR has a large number of report functions (and associated filter functions to be introduced in chapter 5). We will go through some of the main ones. Just remember there is a lot of nuance when it comes to filtering.  

<small>**Important Note**: Do not assign the output of the report function to your genlight object or you will overwrite your genlight object.</small>

###

Let's start with a reminder of the different report functions introduced in the ebook. 

```{r eval = FALSE}
gl.report.sexlinked()

gl.report.callrate()

gl.report.reproducibility()
gl.report.rdepth()

gl.report.monomorphs()
gl.report.secondaries()

gl.report.hamming()
gl.report.taglength()
gl.report.overshoot()

```

###

Don't forget you can use `?gl.report.function`, replacing gl.report.function with the name of the report function you are interested in, to open the help file for more details. For example:

```{r exx1, exercise=TRUE, exercise.setup = "gl"}
?gl.report.callrate()
```

###

If you ran the code in this tutorial it would have opened the help file in your browser, if you run it in your console it will open in Rstudios **Help** pane.

###

Alright let's get to some reports. As is recommended, let's start with sexlinked.

### Sexlinked

Linkage is an important consideration for many analyses. Fortunately, SNPs on separate sequence tags can be considered to assort independently because of the sparse nature of their sampling across the genome. However, if two SNPs occur in a non-recombining block of sequence, they will be co-inherited. This occurs for SNPs that reside in the non-recombining region of the sex chromosomes. They are referred to as sex-linked. `gl.report.sexlinked()` identifies putative sex-linked SNP loci.

###

An important requirement of identifying sexlinked markers is having identified males and females in your dataset. If you do not you will start with reporting on call rate instead.

###

The dragons have a XY system (males being heterogametic) so we need to specify that in the function, using the argument `system =`. You will need to use lower case "xy". 

```{r exfour1, exercise=TRUE, message=TRUE, exercise.setup = "gl"}
gl.report.sexlinked(gl, system = 'xy')
```

###
There is a lot of output and a lot you can do with sex-linked markers that will not be covered in this ebook. For now we are just interested in the number of SNPs that are sex-linked and so will need to be removed when filtering. 

###

It shows us the number of Y-linked loci, sex-biased loci, X-linked loci, and gametologs (refer to the ebook for definitions). Unfortunately we have no Y-linked SNPs that have the most power to identify individuals with unknown sex. 

###

Alright let's move on.

### Call rate "loc"

A filter for Call Rate can be applied to loci and to individuals. A locus can fail to call for an individual because the sequence tag was missed during sequencing (if a service with low read depth) or because of a mutation at one or both of the restriction enzyme sites or internal to the sequence tag. 

###

First let's see the report for call rate on loci of our data `gl`. To do this we need to set the method within `gl.report.callrate()` using `method = "loc"`.

```{r exfour2, exercise=TRUE, exercise.setup = "gl"}
gl.report.callrate(gl, method = 'loc')
```
###
The output shows us a boxplot and histogram of call rate for all the SNPs. It also provides a useful table that shows how many SNPs will be retained at different thresholds. For example we only have 192 SNPs with a call rate of 1, that being the SNP has been called in every individual. 

### 

Each report function is matched with a filter function, e.g. `gl.filter.callrate()` (refer Chapter 5). What threshold would you choose?

### Call Rate "ind"

A second way of filtering on Call Rate is to remove individuals that have sequenced particularly poorly. This may occur if the associated samples are degraded in comparison with other samples. We again first report the Call Rate, this time for individuals.

###

Now lets report on individual call rates. We use the same function as before but make the method equal to `"ind"`.

```{r exfour3, exercise=TRUE, exercise.setup = "gl"}
gl.report.callrate(gl, method='ind')
```

### 

The output will include a list of populations and the Call Rate averaged across individuals, and a list of the top worst individuals in terms of their call rate. This will allow you to make a reasoned judgement on the impact of filtering out individuals.

What threshold would you choose based on individuals?

###
The majority of individuals have call rates less than 0.85. If we filter on loci first, this number will be much higher.

For further help, type `?gl.report.callrate`.

### 

Let's now move on to monomorphs. 

### Monomorphs

`gl.report.monomorphs()` provides a count of polymorphic and monomorphic loci. 

```{r exfour4, exercise=TRUE, exercise.setup = "gl"}
gl.report.monomorphs(gl)
```

The output shows a breakdown of the total number of loci and the number of monomorphic and polymorphic loci. It also counts if there are any loci with missing data for every individual. It appears we have some monomorphic loci. We should probably remove these when we get to the filtering stage.

###

It is not always recommend to remove monomorphic loci, especially if you have subset your data and still intend to compare its genetic measures to the rest of your data. 

### 

Let's now move on to reporting on reproducibility.

### Reproducibility

The reproducibility function summarises repAvg (SNP) or reproducibility (SilicoDArT) values for each locus. DArT runs technical replicates that allow for an assessment of the reliability of the scoring for each locus. 100% means that identical results were obtained for both technical replicates. 

```{r exfour6, exercise=TRUE, exercise.setup = "gl"}
gl.report.reproducibility(gl)
```

###

Matched with `gl.filter.reproducibility()` (refer Chapter 5). 

For further help, type `?gl.report.reproducibility`.

###

Great, next is read depth

### Read depth

The read depth function, `gl.report.rdepth()`, reports an estimate of average read depth for each locus. Adequate read depth is desirable for analyses requiring accurate calls of heterozygotes in particular. 

```{r exfour7, exercise=TRUE, exercise.setup = "gl"}
gl.report.rdepth(gl)
```


###

Matched with `gl.filter.rdepth()` (refer Chapter 5). 

For further help, type `?gl.report.rdepth`.

###

Let's now explore secondaries.

### Secondaries

Diversity Arrays Technology include multiple SNPS in a single sequence tag each as separate records in the data provided with your report. The decision becomes, which SNP to retain, and which SNPs to discard.  One strategy is to leave the filtering of secondaries until last, so that you are considering only those secondaries that have survived the earlier filtering on call rate, reproducibility and read depth. Let's first see how many secondaries we have.

```{r exxx, exercise=TRUE, exercise.setup = "gl"}
gl.report.secondaries(gl)
```

###

Not only does it show us the secondaries, it has the added feature of modelling the frequency distribution of SNP locus counts and estimating the zero class, that is, the number of (unreported) sequence tags that are invariant. This can be useful for correcting some estimates, such as heterozygosity. Check out the ebook for details around estimates of invariant sites, as there are a few caveats. 

###

Matched with `gl.filter.secondaries()`, which will retain only one SNP from each 69bp sequences, i.e. retaining only one sequence tag, using one of two methods: *random* selection or *best* call rate. 

For further help, type `?gl.report.secondaries`.

### Other reporting

There is still a list of functions we have not run through, namely `gl.report.maf`, `gl.report.hamming()`,
`gl.report.taglength()`, and
`gl.report.overshoot()`. How about you try some of them yourself in the R Code box below.


```{r exxx2, exercise=TRUE, exercise.setup = "gl"}

```


###

Now we have a much deeper understanding of the SNPs in our dataset. Let's move on now to get the individual metrics ready for filtering. 

## Worked Ex 4-2: Manipulate
###
You receive additiona information from management. They tell you that the Tuggeranong population is actually more accurately referred to as the Bonython population and that Googon and Royalla are considered the one connected population and usually referred to as the South Canberra population. You go ahead and make the changes they recommend. 

### Renaming populations

To rename a population you can use `gl.rename.pop()`. Use `popNames()` to check that the renaming was successful.


```{r exthree14, exercise=TRUE, exercise.setup = "gl"}
glrename <- gl.rename.pop(gl, old = 'Tuggeranong', new = 'Bonython')
popNames(glrename)

```

###

Great! It is worth noting that the pop names have changed but the ind.metrics have stayed the same, they still hold the old naming convention, Tuggeranong. Feel free to check it above.

### Merging populations

Additionally to renaming, let's try merging our two populations using `gl.merge.pop()`. Use `popNames()` to check again.

```{r exthree15, exercise=TRUE, exercise.setup = "gl"}
glmerge <- gl.merge.pop(gl, old = c('Googong', 'Royalla'), new = 'South Canberra')
popNames(glmerge)

```

###

Even though you have merged the population, you consider the recommendation uniformed, there has been no research on the dispersal between these sampling locations. They could make up one connected population or maybe the they could act as two isolated populations. You decide to leave them as four populations for now, until you get a chance to assess them genetically. 

### Reassigning populations

What you are really interested in is the yearly sampling. So you decide to reassign population to year sampled using `gl.reassign.pop()`. Check that the change was executed and the sample sizes in each year, remeber you can use the function `pop()` and `table()`  to acheive this.

```{r exthree16, exercise=TRUE, exercise.setup = "gl"}
glyear <- gl.reassign.pop(gl, as.pop = 'year')
table(pop(glyear))

```


### Removing individuals
Well that was good to have a bit of practice at manipulating the data, but we decide to keep the original names and populations for now. However, given we don't know the origin of one of the samples, we decide to remove the unknown sample from our data before continuing on to filtering.

###

We can actually do this in two ways, because we are just removing one individual that is uniquely sorted into it's own unknown population, we can use `gl.drop.ind()` or `gl.drop.pop()`. Both these functions contain similar arguments, `ind.list =` or `pop.list =`, for specifying which individual or population you would like to drop. 

###

In a previouse example we identified the individual id as **AA24617**. Try using `gl.drop.ind()`  to remove the unknown individual, and save the new dartR object as `glknown` instead of `gl`.

```{r exthree13, exercise=TRUE, exercise.setup = "gl"}
glknown <- gl.drop.ind(gl, ind.list = 'AA24617')

```

###

Great we have removed an individual. If we wanted to remove more than one we would simply need to privde a list of ids within `c()`. Just like with pops and inds we can also drop loci as well, this is less common because usually we remove loci based on our filtering protocol. 

###

Great know lets continue on using the `glknown`. 

```{r gl2}
gl <- tympo.gl
glknown <- gl.drop.ind(gl, ind.list = 'AA24617')

```


### History

R objects keep a history check out the different histories of `gl`
and `glknown`, which was derived from `gl`. This can be useful as often times there are a lot of steps in preparing genetic data for downstream analyses. The history is located at `gl@other$history`.

###

lets first check `gl` and then `glknown`.

```{r exthree17, exercise=TRUE, exercise.setup = "gl2"}
gl@other$history

```


```{r exthree18, exercise=TRUE, exercise.setup = "gl2"}
glknown@other$history

```

### 

As you can see it kept track of `gl.drop.ind()` as well as the loading in functions. It is also worth noting that it will keep track of any filters used.

Speaking of filters, let's get cracking on filtering our data. Head back to the ebook for everything you need to know about filtering.

## Worked Ex 5-1: Filtering
###

After all those reports we should have a bit of an idea about the type of filtering we plan to do. So, referring back to your reports let's get started with some filtering. 

A good place to start is with call rate. Because filtering on loci and individual call rates are so intertwined sometimes its good to play around with the sequence of these two filters. 

### Visualise 

First let's visualise our missing data using a smear plot `gl.smearplot()`. It may take a little while to run.

```{r exfive, exercise=TRUE, exercise.setup = "gl2"}
gl.smearplot(gl)
```

### Call rate

Let's now start with some call rate filtering. If you can't remember the call rate reports refer back to the reporting section (4-1). 

###

Run the two code blocks below. The first we run a filter for call rate on loci first and then individuals. the second is where we include a lower filter on individuals first before repeating the filtering from the first block. Verbose has been set to zero so it does not include any filtering output, this is for a simpler comparison.

```{r exfive2, exercise=TRUE, exercise.setup = "gl2"}
gl_cr <- gl.filter.callrate(gl, method = 'loc', threshold = 0.95, verbose = 0)
gl_cr <- gl.filter.callrate(gl_cr, method = 'ind', threshold = 0.95, verbose = 0)

nLoc(gl_cr)
nInd(gl_cr)

```

```{r exweird, exercise=TRUE, exercise.setup = "gl2"}
gl_cr <- gl.filter.callrate(gl_cr, method = 'ind', threshold = 0.5, verbose = 0)
gl_cr <- gl.filter.callrate(glknown, method = 'ind', threshold = 0.95, verbose = 0)
gl_cr <- gl.filter.callrate(gl_cr, method = 'loc', threshold = 0.95, verbose = 0)

nLoc(gl_cr)
nInd(gl_cr)

```

### Filtering protocol

Alright now we understand a little about filter sequencing let's put together a filtering protocol. 


```{r exfive3, exercise=TRUE, exercise.setup = "gl2"}
gl_filter <- gl
gl_filter <- gl.filter.callrate(gl_filter, method = 'loc', threshold = 0.95)
gl_filter <- gl.filter.callrate(gl_filter, method = 'ind', threshold = 0.95)
gl_filter <- gl.filter.reproducibility(gl_filter, threshold = 0.99)
gl_filter <- gl.filter.rdepth(gl_filter, lower = 5, upper = 60)
gl_filter <- gl.filter.monomorphs(gl_filter)
gl_filter <- gl.filter.secondaries(gl_filter, method = 'random')


```


```{r glfilt}
gl <- tympo.gl
pop(gl) <- gl@other$ind.metrics$year
glknown <- gl.drop.ind(gl, ind.list = 'AA24617')

gl_filter <- glknown
gl_filter <- gl.filter.callrate(gl_filter, method = 'loc', threshold = 0.95)
gl_filter <- gl.filter.callrate(gl_filter, method = 'ind', threshold = 0.95)
gl_filter <- gl.filter.reproducibility(gl_filter, threshold = 0.99)
gl_filter <- gl.filter.rdepth(gl_filter, lower = 5, upper = 60)
gl_filter <- gl.filter.monomorphs(gl_filter)
gl_filter <- gl.filter.secondaries(gl_filter, method = 'random')

```

## Worked Ex 5-3: Recalculating

Remember, the locus metrics are no longer valid if individuals or populations are deleted from the dataset. For example, if you filter out a population for which the individuals have particularly bad call rates, then the call rate parameter held in the locus metrics will no longer be accurate. It will need to be recalculated. This is true of many of the locus metrics.

So, after filtering your data, it is wise to recalculate the locus metrics with


```{r exfive4, exercise=TRUE, exercise.setup = "glfilt"}
gl_filter <- gl.recalc.metrics(gl_filter)
gl_filter
```

```{r exfive4-solution}
gl_filter <- gl.recalc.metrics(gl_filter)
```

 

Similarly, when filtering has resulted in removal of some individuals or populations, variation at several loci may be lost. Some loci may even be scored as missing across all individuals. You may wish to remove these monomorphic loci from your dataset with


```{r exfive5, exercise=TRUE, exercise.setup = "glfilt"}
gl_filter <- gl.filter.monomorphs(gl_filter)
```

```{r exfive5-solution}
gl_filter <- gl.filter.monomorphs(gl_filter)
```

Note that many functions have a mono.rm and recalc parameters that allow you to remove monomorphic loci or recalculate metrics on the fly.

It is not a fatal error to forget to recalculate the locus metrics because dartR scripts will detect if they have not been recalculated and rectify this before they a particular locus metric is needed. 






